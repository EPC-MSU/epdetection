{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Eyepoint_PCA.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor,Resize, Grayscale, Normalize\n",
        "import matplotlib.pyplot as plt\n",
        "import zipfile\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import os\n",
        "import pandas as pd\n",
        "from torch.utils.data import Dataset\n",
        "import glob\n",
        "import cv2\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.tensorboard import SummaryWriter"
      ],
      "metadata": {
        "id": "BOP88xwG3t-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip train_x1.zip"
      ],
      "metadata": {
        "id": "u0SE2Gm1z9eE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class My_class(Dataset):\n",
        "    def __init__(self, classes_paths, transforms=None, target_transform=None):\n",
        "        #print(glob.glob(data_dir))\n",
        "        self.classes = []\n",
        "        self.images = []\n",
        "        self.transform = transforms\n",
        "        for actual_class in classes_paths:\n",
        "            if actual_class == 1:\n",
        "                print(\"\")\n",
        "            paths = classes_paths[actual_class]\n",
        "            for path in paths:\n",
        "                # print(\"Loading \" + path)\n",
        "                for top, dirs, files in os.walk(path):\n",
        "                    for i, name in enumerate(files):\n",
        "                        if not os.path.isfile(top + \"//\" + name):\n",
        "                            continue\n",
        "                        try:\n",
        "                            imag = cv2.imread(top + \"//\" + name)\n",
        "                        except Exception:\n",
        "                            continue\n",
        "                        self.images.append(imag)\n",
        "                        self.classes.append(actual_class)\n",
        "        self.images, self.classes = np.array(self.images), torch.tensor(np.array(self.classes), dtype=torch.int64)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if self.transform==None:\n",
        "            return self.images[idx], self.classes[idx]\n",
        "        else:\n",
        "            return self.transform(np.array(self.images[idx]).astype(np.float32)), self.classes[idx]"
      ],
      "metadata": {
        "id": "GsPDEOQM3rnT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CLASSES_PATHS = {\n",
        "    0: [\"train_x1//SMD0402_CL//correct\"],\n",
        "    1: [\"train_x1//SMD0402_R//correct\"],\n",
        "    2: [\"train_x1//SMD0603_CL//correct\"],\n",
        "    3: [\"train_x1//SMD0603_D//correct\"],\n",
        "    4: [\"train_x1//SMD0603_R//correct\"],\n",
        "    5: [\"train_x1//SMD0805_CL//correct\"],\n",
        "    6: [\"train_x1//SMD0805_R//correct\"],\n",
        "    7: [\"train_x1//SMD1206_C//correct\"],\n",
        "    8: [\"train_x1//SMD1206_R//correct\"],\n",
        "    9: [\"train_x1//SMD1210_C//correct\"],\n",
        "    10: [\"train_x1//2-SMD//correct\"],\n",
        "    11: [\"train_x1//SMA//correct\"],\n",
        "    12: [\"train_x1//SMB//correct\"],\n",
        "    13: [\"train_x1//SOD110//correct\"],\n",
        "    14: [\"train_x1//SOD323F//correct\"],\n",
        "    15: [\"train_x1//SOD523//correct\"],\n",
        "    16: [\"train_x1//SOT23-5//correct\"],\n",
        "    17: [\"train_x1//SOT23-6//correct\"],\n",
        "    18: [\"train_x1//SOT143//correct\"],\n",
        "    19: [\"train_x1//SOT323//correct\"],\n",
        "    20: [\"train_x1//SOT323-5//correct\"],\n",
        "    21: [\"train_x1//SOT343//correct\"],\n",
        "    22: [\"train_x1//SOT363//correct\"],\n",
        "    23: [\"train_x1//SOT523//correct\"],\n",
        "    24: [\"train_x1//SOT723//correct\"],\n",
        "    25: [\"train_x1//DIP-%d//correct\"],\n",
        "    26: [\"train_x1//LQFP0.4-%d//correct\"],\n",
        "    27: [\"train_x1//LQFP0.5-%d&TFSOP-%d//correct\"],\n",
        "    28: [\"train_x1//LQFP0.8-%d//correct\"],\n",
        "    29: [\"train_x1//LQFP0.65-%d&SSOP-%d//correct\"],\n",
        "    30: [\"train_x1//SOIC-%d//correct\"]\n",
        "}\n",
        "transforms = torchvision.transforms.Compose([ToTensor(),\n",
        "                                             Grayscale(1),\n",
        "                                             Resize([32, 32]),\n",
        "                                             Normalize(mean=0, std=1)])\n",
        "\n",
        "dataset = My_class(CLASSES_PATHS, transforms)"
      ],
      "metadata": {
        "id": "5ffuJ1133kPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images, labels = [], []\n",
        "for img, label in dataset:\n",
        "    images.append(img)\n",
        "    labels.append(label)"
      ],
      "metadata": {
        "id": "6f6cXON74W5L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = torch.stack(images)\n",
        "labels = torch.stack(labels)"
      ],
      "metadata": {
        "id": "y-gaIzBJ40ht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images.squeeze().shape"
      ],
      "metadata": {
        "id": "cw2uMzBe5dBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dimages = images.view(8164, 1024)\n",
        "dimages.shape"
      ],
      "metadata": {
        "id": "P_1qbXmJ5ric"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RD-afLAqz52f"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# launching Tensorboard in Colab\n",
        "def reinit_tensorboard(clear_log = True):\n",
        "  # Log files are read from this directory: \n",
        "  logs_base_dir = \"runs\"\n",
        "  if clear_log:\n",
        "    # clear logs \n",
        "    #!rm -rfv {logs_base_dir}/*\n",
        "    shutil.rmtree(logs_base_dir, ignore_errors = True)\n",
        "    os.makedirs(logs_base_dir, exist_ok=True)\n",
        "  # Colab magic\n",
        "  %load_ext tensorboard\n",
        "  %tensorboard --logdir {logs_base_dir}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import tensorflow as tf\n",
        "import tensorboard as tb\n",
        "import numpy\n",
        "tf.io.gfile = tb.compat.tensorflow_stub.io.gfile\n",
        "\n",
        "reinit_tensorboard()"
      ],
      "metadata": {
        "id": "t96nsJ9C8vsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "writer = SummaryWriter(comment = \"EyePoint\")\n",
        "np_f = numpy.array(dimages)\n",
        "writer.add_embedding(mat=np_f, metadata=labels)\n",
        "writer.close()"
      ],
      "metadata": {
        "id": "fFkt_Wtd7jg1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}